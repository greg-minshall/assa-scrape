[[http://www.crummy.com/software/BeautifulSoup/][BeautifulSoup]]

it seems that the structure of the file is such that the structure
looks something like

- font class="dayHeader" t
- font class="sessionTime" t
- font class="sessionLocation" t
- font class="sessionSource" t
- div class="sessionTitle" t
- div class="presiding"
  - font class="name" t
  - font class="affiliation" t
- div class="paper"
  - font class="paperTitle" t
  - div class="author"
    - font class="name" t
    - font class="affiliation" t
  - div id=paper_NNNNN_abstract ttt

L1:
find first dayHeader
L3:
get next sibling
is dayHeader?  yes, go to L1
is not sessionTime? error E1
L2:
collect sessionLocation, sessionSource, sessionTitle, presiding
get next sibling
is dayHeader?  yes, go to L1
is sessionTime?  yes, go to L2
is not paper?  error E2
collect paperTitle
collect authors
collect abstract
go to L3

for layout:

- dayHeader: **
- sessionTime: ***
- session (Time, Location, Source, Title, presiding, panelist}: ****
  so, duplicate sessionTime, to get info closer to reader
- each paper (Title, author): *****
- abstract (hyperlink): ******

when get, e.g., new sessionTime, check to see if same as current.  if
same, don't emit anything; else, emit a new "** Session time: %"

but, alternative doc would have "Source" at second level.

#+name: markers
| section     | marker |
|-------------+--------|
| day         | **     |
| time        | ***    |
| session     | ****   |
| paper       | *****  |
| postsession | ****   |

#+name: sections
| tag                | section     | beginning |
|--------------------+-------------+-----------|
| dayHeader          | day         | y         |
| sessionTime        | time        | y         |
| sessionLocation    | session     | y         |
| sessionSource      | session     | n         |
| sessionTitle       | session     | n         |
| presiding          | session     | n         |
| panelist           | session     | n         |
| topic              | session     | n         |
| sessionJEL         | session     | n         |
| sessionType        | session     | n         |
| paper              | paper       | y         |
| paperTitle         | paper       | n         |
| author             | paper       | n         |
| hyperlink          | paper       | n         |
| name               |             |           |
| affiliation        |             |           |
| discussantsSection | postsession | y         |
| discussant         | postsession | n         |
  

#+BEGIN_SRC python :session py :var fname="aea-2016-assa-prelim.html" :var sections=sections :var markers=markers
  def begin_day():
      pass

  def in_day(cur):
      cur_day = rstring(cur)
      print markers['day'][0], cur_day

  def end_day():
      pass

  def begin_time():
      pass

  def in_time(cur):
      cur_time = rstring(cur)
      print markers['time'][0], cur_time

  def end_time():
      pass

  def begin_session():
      global session
      session = {}

  def in_session(cur):
      cl = rclass(cur)
      session[cl] = cur
      if cl == 'sessionTitle':
          print markers['session'][0], cur.contents[0].string.strip()

  def end_session():
      pass

  def begin_paper():
      global paper
      paper = {}

  def in_paper(cur):
      cl = rclass(cur)
      paper[cl] = cur
      if cl == 'paperTitle':
          print markers['paper'][0], cur.contents[0].string.strip()

  def end_paper():
      pass

  def begin_postsession():
      pass

  def in_postsession(cur):
      pass

  def end_postsession():
      pass

  # this is the non-semantic part of our process

  def rstring(cur):
      try:
          if (type(cur.contents[0]).__name__ == "NavigableString") & (len(cur.contents) == 1):
              return cur.string.strip()
          else:
              return ""
      # http://stackoverflow.com/a/730778
      except Exception:
          return ""

  def rclass(cur):
      try:
          return cur['class'][0]
      except Exception:
          return ""

  def nextsib(cur):
      x = cur.next_sibling;
      while type(x).__name__ == "NavigableString":
          x = x.next_sibling
      return x

  def nameaffil(cur):             # XXX descend to get name, affiliation
      kind = cur[u'class']
      name = cur.find("font", "name")
      affil = nextsib(name)
      mass(affil, u'affiliation')
      (name, affil)

  def firstchild(cur):
      try:
          child = cur.contents[0]
          if type(child).__name__ == "NavigableString":
              return nextsib(child)
          else:
              return child
      except Exception:
          pass

  def listtodict(l):
      a = {}
      for i in l:
          a[i[0]] = i[1:]
      return a

  def walk(me, level=""):
      global lastsection, section, lastme
      while me:
          lastme = me
          # print "%s%s:  %s" % (level, rclass(me), rstring(me))
          # print "%s%s:  %s" % (level, rclass(me), rstring(me))
          class_ = rclass(me)
          section = sections[class_][0]
          if section == "":
              section = lastsection
          if section != lastsection: # changing section
              if lastsection != "":
                  eval("end_%s()" % lastsection) # end the previous section
              lastsection = section
              eval("begin_%s()" % section)       # start the new section
          eval("in_%s(me)" % section)
          # print "%s%s:  %s" % (level, class_, rstring(me))
          walk(firstchild(me), level+" ")    # go down
          me = nextsib(me)        # continue this level


  lastsection = ""
  sections = listtodict(sections)
  sections[''] = ['', 'n']        # XXX
  markers = listtodict(markers)
  markers[''] = ''                # XXX
#+END_SRC

#+RESULTS:


#+BEGIN_SRC python :var fname="aea-2016-assa-prelim.html" :session py
  from bs4 import BeautifulSoup
  # http://stackoverflow.com/questions/11339955/python-string-encode-decode
  html = open(fname, "r").read()

  # need to get rid of <hr>, <br> (mess up beautifulsoup)
  # http://stackoverflow.com/questions/17639031/beautifulsoup-sibling-structure-with-br-tags

  # and, <strong>, <em>, seem to get in our way (by making cur.string =
  # "", needing to descend

  # XXX -- should be some more general way of doing this!
  for i in ["<br>", "<hr>", "<strong>", "</strong>", "<em>", "</em>"]:
      html = html.replace(i, "")

  # from
  # http://www.crummy.com/software/BeautifulSoup/bs4/doc/
  soup = BeautifulSoup(html, 'html.parser', from_encoding="utf-8")
  print("done")

  sessiontimes = list(set(soup.find_all('font', "sessionTime"))).sort()
#+END_SRC

#+RESULTS:


#+BEGIN_SRC python :var html="file:aea-2016-assa-prelim.html"
# http://stackoverflow.com/questions/19460403/html-file-parsing-in-python
from bs4 import BeautifulSoup
from pprint import pprint

soup = BeautifulSoup(html)
h2s = soup.select("h2") #get all h2 elements
tables = soup.select("table") #get all tables

first = True
title =""
players = []
for i,table in enumerate(tables):
    if first:
         #every h2 element has 2 tables. table size = 8, h2 size = 4
         #so for every 2 tables 1 h2
         title =  h2s[int(i/2)].text
    for tr in table.select("tr"):
        player = (title,) #create a player
        for td in tr.select("td"):
            player = player + (td.text,) #add td info in the player
        if len(player) > 1: 
            #If the tr contains a player and its not only ("Goalkeaper") add it
            players.append(player)
    first = not first
pprint(players)
#+END_SRC

#+RESULTS:
: None
