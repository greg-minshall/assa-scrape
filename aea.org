[[http://www.crummy.com/software/BeautifulSoup/][BeautifulSoup]]

it seems that the structure of the file is such that the structure
looks something like

- font class="dayHeader" t
- font class="sessionTime" t
- font class="sessionLocation" t
- font class="sessionSource" t
- div class="sessionTitle" t
- div class="presiding"
  - font class="name" t
  - font class="affiliation" t
- div class="paper"
  - font class="paperTitle" t
  - div class="author"
    - font class="name" t
    - font class="affiliation" t
  - div id=paper_NNNNN_abstract ttt

L1:
find first dayHeader
L3:
get next sibling
is dayHeader?  yes, go to L1
is not sessionTime? error E1
L2:
collect sessionLocation, sessionSource, sessionTitle, presiding
get next sibling
is dayHeader?  yes, go to L1
is sessionTime?  yes, go to L2
is not paper?  error E2
collect paperTitle
collect authors
collect abstract
go to L3

#+BEGIN_SRC python :var fname="aea-2016-assa-prelim.html" :session py
  def mass(cur, expected):
      assert cur['class'] == [expected], "expected %s, got %s" % (expected, cur['class'])

  def nextsib(cur):
      x = cur.next_sibling;
      while type(x).__name__ == "NavigableString":
          x = x.next_sibling
      print x.contents[0].string
      return x

  def nameaffil(cur):             # XXX descend to get name, affiliation
      kind = cur[u'class']
      name = cur.find("font", "name")
      print name.contents[0].string
      affil = nextsib(name)
      mass(affil, u'affiliation')
      (name, affil)

  def campbells(soup):
      global dayheader, stime, slocation, ssource, stitle
      global presiding, panelist, paper, ptitle, author, id
      dayheader = soup.find("font", "dayHeader")
      print dayheader.string            # XXX
      # http://stackoverflow.com/questions/17639031/beautifulsoup-sibling-structure-with-br-tags
      while (dayheader['class'] == [u'dayHeader']):
          stime = nextsib(dayheader)
          while (stime['class'] == [u'sessionTime']):
              slocation = nextsib(stime)
              mass(slocation, u'sessionLocation')
              ssource = nextsib(slocation)
              mass(ssource, u'sessionSource')
              stitle = nextsib(ssource)
              mass(stitle, u'sessionTitle')
              presiding = nextsib(stitle)
              mass(presiding, u'presiding')
              nameaffil(presiding)
              panelist = nextsib(presiding)
              while (panelist['class'] == [u'panelist']):
                  nameaffil(panelist)
                  panelist = nextsib(panelist)
              paper = panelist    # wasn't a panelist, so
              while (paper['class'] == [u'paper']):
                  ptitle = nextsib(paper)
                  mass(ptitle, u'paperTitle')
                  author = nextsib(ptitle)
                  while (author['class'] == [u'author']):
                      nameaffil(author)
                  id = ptitle['id']
                  paper = nextsib(id)
              stime = paper       # wasn't a paper, so...
          dayheader = stime       # wasn't session time, so...
#+END_SRC

#+RESULTS:


#+BEGIN_SRC python :var fname="aea-2016-assa-prelim.html" :session py
  from bs4 import BeautifulSoup
  # http://stackoverflow.com/questions/11339955/python-string-encode-decode
  html = open(fname, "r").read()

  # need to get rid of <hr>, <br> (mess up beautifulsoup)
  # http://stackoverflow.com/questions/17639031/beautifulsoup-sibling-structure-with-br-tags

  html = html.replace("<br>", "")
  html = html.replace("<hr>", "")

  # from
  # http://www.crummy.com/software/BeautifulSoup/bs4/doc/
  soup = BeautifulSoup(html, 'html.parser', from_encoding="utf-8")
  print("done")

  sessiontimes = list(set(soup.find_all('font', "sessionTime"))).sort()
#+END_SRC

#+RESULTS:


#+BEGIN_SRC python :var html="file:aea-2016-assa-prelim.html"
# http://stackoverflow.com/questions/19460403/html-file-parsing-in-python
from bs4 import BeautifulSoup
from pprint import pprint

soup = BeautifulSoup(html)
h2s = soup.select("h2") #get all h2 elements
tables = soup.select("table") #get all tables

first = True
title =""
players = []
for i,table in enumerate(tables):
    if first:
         #every h2 element has 2 tables. table size = 8, h2 size = 4
         #so for every 2 tables 1 h2
         title =  h2s[int(i/2)].text
    for tr in table.select("tr"):
        player = (title,) #create a player
        for td in tr.select("td"):
            player = player + (td.text,) #add td info in the player
        if len(player) > 1: 
            #If the tr contains a player and its not only ("Goalkeaper") add it
            players.append(player)
    first = not first
pprint(players)
#+END_SRC

#+RESULTS:
: None
