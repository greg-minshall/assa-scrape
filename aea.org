[[http://www.crummy.com/software/BeautifulSoup/][BeautifulSoup]]

it seems that the structure of the file is such that the structure
looks something like

- font class="dayHeader" t
- font class="sessionTime" t
- font class="sessionLocation" t
- font class="sessionSource" t
- div class="sessionTitle" t
- div class="presiding"
  - font class="name" t
  - font class="affiliation" t
- div class="paper"
  - font class="paperTitle" t
  - div class="author"
    - font class="name" t
    - font class="affiliation" t
  - div id=paper_NNNNN_abstract ttt

L1:
find first dayHeader
L3:
get next sibling
is dayHeader?  yes, go to L1
is not sessionTime? error E1
L2:
collect sessionLocation, sessionSource, sessionTitle, presiding
get next sibling
is dayHeader?  yes, go to L1
is sessionTime?  yes, go to L2
is not paper?  error E2
collect paperTitle
collect authors
collect abstract
go to L3

for layout:

- dayHeader: **
- sessionTime: ***
- session (Time, Location, Source, Title, presiding, panelist}: ****
  so, duplicate sessionTime, to get info closer to reader
- each paper (Title, author): *****
- abstract (hyperlink): ******

when get, e.g., new sessionTime, check to see if same as current.  if
same, don't emit anything; else, emit a new "** Session time: %"

but, alternative doc would have "Source" at second level.

#+name: markers
| section     | marker |
|-------------+--------|
| day         | **     |
| time        | ***    |
| session     | ****   |
| paper       | *****  |
| postsession | ****   |

#+name: sections
| tag                | section     | marker |
|--------------------+-------------+--------|
| dayHeader          | day         | **     |
| sessionTime        | time        | ***    |
| sessionTitle       | session     | ****   |
| topic              | session     | *****  |
| sessionJEL         | session     |        |
| sessionSource      | session     | -      |
| sessionType        | session     |        |
| sessionLocation    | session     | -      |
| presiding          | session     | -      |
| panelist           | session     | -      |
| paper              | paper       |        |
| paperTitle         | paper       | *****  |
| author             | paper       | -      |
| hyperlink          | paper       | ****** |
| name               |             |        |
| affiliation        |             |        |
| discussantsSection | postsession | *****  |
| discussant         | postsession |        |


*** $discussant

#+BEGIN_SRC python :session py :var fname="aea-2016-assa-prelim.html" :var sections=sections :var markers=markers
  def begin_day():
      pass

  def in_day(cur):
      global cur_day
      if cur_day != rstring(cur):
          cur_day = rstring(cur)
          print markers['day'][0], cur_day

  def end_day():
      pass

  def begin_time():
      pass

  def in_time(cur):
      global cur_time
      if cur_time != rstring(cur):
          cur_time = rstring(cur)
          print markers['time'][0], cur_time

  def end_time():
      pass

  # session.format = 
  # "**** $sessionTitle
  # - $sessionJEL
  # - $sessionSource
  # - $sessionType
  # - $sessionLocation
  # - presiding: $presiding
  # [- $panelist]*\n"

  def begin_session():
      global session, papers
      session = {}
      papers = []                 # new session, new set of papers

  def in_session(cur):
      session[rclass(cur)] = cur

  def end_session():
      if 'sessionTitle' in session:
          print "%s %s" % (sections['sessionTitle'][1], session['sessionTitle'].contents[0].strip())
          if firstchild(session['sessionTitle']) :
              print "- JEL:", firstchild(session['sessionTitle']).string.strip()
      else:
          print "%s <unnamed session>" % markers['session'][0]
      print "-", session['sessionSource'].string.strip()
      if 'sessionType' in session:
          print "-", session['sessionType'].string.strip()
      print "-", session['sessionLocation'].string.strip()
      print "-", nameaffils(session['presiding'])


  # paper.format =
  # "***** $paperTitle
  # - $name ($affiliation)
  # ****** abstract
  # $abstract

  def begin_paper():
      pass

  def in_paper(cur):
      global papers
      papers += [cur]

  def end_paper():
      for paper in papers:
          title = paper.find(class_="paperTitle").string.strip()
          author = paper.find(class_="author")
          print "*****", title
          print "- %s" % nameaffils(author)
          print "****** abstract:"
          if paper.find(class_="hyperlink"):
              abstract = nextsib(paper.find(class_="hyperlink")).string.strip()
              print abstract


  def begin_postsession():
      global postsession
      postsession = []

  def in_postsession(cur):
      global postsession
      postsession = postsession + [cur]

  def end_postsession():
      if "postsession" in globals():
          global postsession
          print "in end_postsession"
          dprefix = sections['discussantsSection'][1]
          for dsection in postsession:
              for d in dsection.children:      # discussant
                  if not navigablestring(d):
                      if rclass(d) != "discussant":
                          print d, " class: ", rclass(d), type(d), type(d).__name__, navigablestring(d)
                          raise NotImplementedError
                      print dprefix, "discussant: %s" % nameaffils(d)

  # some semantic-aware utility routines

  def nameaffils(cur, separator=", "): # XXX descend to get names and affiliations
      result = ""
      for name, affil in zip(cur.findAll(class_="name"), cur.findAll(class_="affiliation")):
          result = result + separator + name.string.strip() + " " + affil.string.strip()
      return result

  # this is the non-semantic part of our process

  def navigablestring(cur):
      return type(cur).__name__ == "NavigableString"


  def rstring(cur):
      try:
          if navigablestring(cur.contents[0]) & (len(cur.contents) == 1):
              return cur.string.strip()
          else:
              return ""
      # http://stackoverflow.com/a/730778
      except Exception:
          return ""

  def rclass(cur):
      try:
          return cur['class'][0]
      except Exception:
          return ""

  def nextsib(cur):
      x = cur.next_sibling;
      while type(x).__name__ == "NavigableString":
          x = x.next_sibling
      return x

  def firstchild(cur):
      try:
          child = cur.contents[0]
          if type(child).__name__ == "NavigableString":
              return nextsib(child)
          else:
              return child
      except Exception:
          pass

  def listtodict(l):
      a = {}
      for i in l:
          a[i[0]] = i[1:]
      return a

  def walk(me, level=""):
      global lastsection, section, lastme
      while me:
          lastme = me
          # print "%s%s:  %s" % (level, rclass(me), rstring(me))
          # print "%s%s:  %s" % (level, rclass(me), rstring(me))
          class_ = rclass(me)
          section = sections[class_][0]
          if section == "":
              section = lastsection
          if section != lastsection: # changing section
              if lastsection != "":
                  eval("end_%s()" % lastsection) # end the previous section
              lastsection = section
              eval("begin_%s()" % section)       # start the new section
          eval("in_%s(me)" % section)
          # print "%s%s:  %s" % (level, class_, rstring(me))
          me = nextsib(me)        # continue this level


  lastsection = ""
  sections = listtodict(sections)
  sections[''] = ['']
  markers = listtodict(markers)
  markers[''] = ''                # XXX

  cur_day = ""
  cur_time = ""
#+END_SRC

#+RESULTS:
: , Jan Kregel (Levy Economics Institute of Bard College)


#+BEGIN_SRC python :var fname="aea-2016-assa-prelim.html" :session py
  from bs4 import BeautifulSoup
  # http://stackoverflow.com/questions/11339955/python-string-encode-decode
  html = open(fname, "r").read()

  # need to get rid of <hr>, <br> (mess up beautifulsoup)
  # http://stackoverflow.com/questions/17639031/beautifulsoup-sibling-structure-with-br-tags

  # and, <strong>, <em>, seem to get in our way (by making cur.string =
  # "", needing to descend

  # XXX -- should be some more general way of doing this!
  for i in ["<br>", "<hr>", "<strong>", "</strong>", "<em>", "</em>"]:
      html = html.replace(i, "")

  # from
  # http://www.crummy.com/software/BeautifulSoup/bs4/doc/
  soup = BeautifulSoup(html, 'html.parser', from_encoding="utf-8")
  print("done")

  sessiontimes = list(set(soup.find_all('font', "sessionTime"))).sort()
#+END_SRC

#+RESULTS:


#+BEGIN_SRC python :var html="file:aea-2016-assa-prelim.html"
# http://stackoverflow.com/questions/19460403/html-file-parsing-in-python
from bs4 import BeautifulSoup
from pprint import pprint

soup = BeautifulSoup(html)
h2s = soup.select("h2") #get all h2 elements
tables = soup.select("table") #get all tables

first = True
title =""
players = []
for i,table in enumerate(tables):
    if first:
         #every h2 element has 2 tables. table size = 8, h2 size = 4
         #so for every 2 tables 1 h2
         title =  h2s[int(i/2)].text
    for tr in table.select("tr"):
        player = (title,) #create a player
        for td in tr.select("td"):
            player = player + (td.text,) #add td info in the player
        if len(player) > 1: 
            #If the tr contains a player and its not only ("Goalkeaper") add it
            players.append(player)
    first = not first
pprint(players)
#+END_SRC

#+RESULTS:
: None
