[[http://www.crummy.com/software/BeautifulSoup/][BeautifulSoup]]

it seems that the structure of the file is such that the structure
looks something like

- font class="dayHeader" t
- font class="sessionTime" t
- font class="sessionLocation" t
- font class="sessionSource" t
- div class="sessionTitle" t
- div class="presiding"
  - font class="name" t
  - font class="affiliation" t
- div class="paper"
  - font class="paperTitle" t
  - div class="author"
    - font class="name" t
    - font class="affiliation" t
  - div id=paper_NNNNN_abstract ttt

L1:
find first dayHeader
L3:
get next sibling
is dayHeader?  yes, go to L1
is not sessionTime? error E1
L2:
collect sessionLocation, sessionSource, sessionTitle, presiding
get next sibling
is dayHeader?  yes, go to L1
is sessionTime?  yes, go to L2
is not paper?  error E2
collect paperTitle
collect authors
collect abstract
go to L3

for layout:

- dayHeader: **
- sessionTime: ***
- session (Time, Location, Source, Title, presiding, panelist}: ****
  so, duplicate sessionTime, to get info closer to reader
- each paper (Title, author): *****
- abstract (hyperlink): ******

when get, e.g., new sessionTime, check to see if same as current.  if
same, don't emit anything; else, emit a new "** Session time: %"

but, alternative doc would have "Source" at second level.

#+name: sections
| section     | marker |
|-------------+--------|
| day         | **     |
| time        | ***    |
| session     | ****   |
| paper       | *****  |
| postsession | ****   |

#+name: tags
| tag                | section     |
|--------------------+-------------|
| dayHeader          | day         |
| sessionTime        | time        |
| sessionLocation    | session     |
| sessionSource      | session     |
| sessionTitle       | session     |
| presiding          | session     |
| panelist           | session     |
| topic              | session     |
| sessionJEL         | session     |
| sessionType        | session     |
| paper              | paper       |
| paperTitle         | paper       |
| author             | paper       |
| hyperlink          | paper       |
| name               |             |
| affiliation        |             |
| discussantsSection | postsession |
| discussant         | postsession |
  

#+BEGIN_SRC python :session py :var fname="aea-2016-assa-prelim.html" :var sections=sections :var tags=tags
  def rstring(cur):
      try:
          if (type(cur.contents[0]).__name__ == "NavigableString") & (len(cur.contents) == 1):
              return cur.string
          else:
              return ""
      # http://stackoverflow.com/a/730778
      except Exception:
          return ""

  def rclass(cur):
      try:
          return cur['class'][0]
      except Exception:
          return ""

  def mass(cur, expected):
      assert cur['class'] == [expected], "expected %s, got %s" % (expected, cur['class'])

  def nextsib(cur):
      x = cur.next_sibling;
      while type(x).__name__ == "NavigableString":
          x = x.next_sibling
      return x

  def nameaffil(cur):             # XXX descend to get name, affiliation
      kind = cur[u'class']
      name = cur.find("font", "name")
      affil = nextsib(name)
      mass(affil, u'affiliation')
      (name, affil)

  def campbells(soup):
      global dayheader, stime, slocation, ssource, stitle
      global presiding, panelist, paper, ptitle, author, id
      dayheader = soup.find(class_="dayHeader")
      # http://stackoverflow.com/questions/17639031/beautifulsoup-sibling-structure-with-br-tags
      while (dayheader['class'] == [u'dayHeader']):
          stime = nextsib(dayheader)
          while (stime['class'] == [u'sessionTime']):
              slocation = nextsib(stime)
              mass(slocation, u'sessionLocation')
              ssource = nextsib(slocation)
              mass(ssource, u'sessionSource')
              stitle = nextsib(ssource)
              mass(stitle, u'sessionTitle')
              presiding = nextsib(stitle)
              mass(presiding, u'presiding')
              nameaffil(presiding)
              panelist = nextsib(presiding)
              while (panelist['class'] == [u'panelist']):
                  nameaffil(panelist)
                  panelist = nextsib(panelist)
              paper = panelist    # wasn't a panelist, so
              while (paper['class'] == [u'paper']):
                  ptitle = nextsib(paper)
                  mass(ptitle, u'paperTitle')
                  author = nextsib(ptitle)
                  while (author['class'] == [u'author']):
                      nameaffil(author)
                  id = ptitle['id']
                  paper = nextsib(id)
              stime = paper       # wasn't a paper, so...
          dayheader = stime       # wasn't session time, so...

  def firstchild(cur):
      try:
          child = cur.contents[0]
          if type(child).__name__ == "NavigableString":
              return nextsib(child)
          else:
              return child
      except Exception:
          pass

  def listtodict(l):
      a = {}
      for i in l:
          a[i[0]] = i[1]
      return a

  def walk(me, level=""):
      while me:
          # print "%s%s:  %s" % (level, rclass(me), rstring(me))
          print "%s%s:  %s" % (level, tags[rclass(me)], rstring(me))
          t = tags[rclass(me)]
          s = sections[t]
          walk(firstchild(me), level+" ")    # go down
          me = nextsib(me)        # continue this level

  tags = listtodict(tags)
  tags[''] = ''                   # XXX
  sections = listtodict(sections)
  sections[''] = ''
#+END_SRC

#+RESULTS:


#+BEGIN_SRC python :var fname="aea-2016-assa-prelim.html" :session py
  from bs4 import BeautifulSoup
  # http://stackoverflow.com/questions/11339955/python-string-encode-decode
  html = open(fname, "r").read()

  # need to get rid of <hr>, <br> (mess up beautifulsoup)
  # http://stackoverflow.com/questions/17639031/beautifulsoup-sibling-structure-with-br-tags

  # and, <strong>, <em>, seem to get in our way (by making cur.string =
  # "", needing to descend
  for i in ["<br>", "<hr>", "<strong>", "</strong>", "<em>", "</em>"]:
      html = html.replace(i, "")

  # from
  # http://www.crummy.com/software/BeautifulSoup/bs4/doc/
  soup = BeautifulSoup(html, 'html.parser', from_encoding="utf-8")
  print("done")

  sessiontimes = list(set(soup.find_all('font', "sessionTime"))).sort()
#+END_SRC

#+RESULTS:


#+BEGIN_SRC python :var html="file:aea-2016-assa-prelim.html"
# http://stackoverflow.com/questions/19460403/html-file-parsing-in-python
from bs4 import BeautifulSoup
from pprint import pprint

soup = BeautifulSoup(html)
h2s = soup.select("h2") #get all h2 elements
tables = soup.select("table") #get all tables

first = True
title =""
players = []
for i,table in enumerate(tables):
    if first:
         #every h2 element has 2 tables. table size = 8, h2 size = 4
         #so for every 2 tables 1 h2
         title =  h2s[int(i/2)].text
    for tr in table.select("tr"):
        player = (title,) #create a player
        for td in tr.select("td"):
            player = player + (td.text,) #add td info in the player
        if len(player) > 1: 
            #If the tr contains a player and its not only ("Goalkeaper") add it
            players.append(player)
    first = not first
pprint(players)
#+END_SRC

#+RESULTS:
: None
